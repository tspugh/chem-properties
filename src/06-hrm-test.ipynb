{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ad503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696835c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                             SMILES  Tg       FFV  \\\n",
      "0   87817                         *CC(*)c1ccccc1C(=O)OCCCCCC NaN  0.374645   \n",
      "1  106919  *Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5... NaN  0.370410   \n",
      "2  388772  *Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(... NaN  0.378860   \n",
      "3  519416  *Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)... NaN  0.387324   \n",
      "4  539187  *Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N... NaN  0.355470   \n",
      "\n",
      "         Tc  Density  Rg  \n",
      "0  0.205667      NaN NaN  \n",
      "1       NaN      NaN NaN  \n",
      "2       NaN      NaN NaN  \n",
      "3       NaN      NaN NaN  \n",
      "4       NaN      NaN NaN  \n",
      "7973\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "full_train_data = pd.read_csv(\"../data/train.csv\")\n",
    "print(full_train_data.head())\n",
    "print(len(full_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2737b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "from typing import List, Tuple, Dict\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from kmeans_hrm_model import KMeansCarry\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Projektpfade und Trainingshyperparameter\n",
    "PROJECT_ROOT = \"/home/thomaspugh/projects/chem-properties\"\n",
    "DATA_CSV = os.path.join(PROJECT_ROOT, \"data\", \"train.csv\")\n",
    "CHECKPOINT_DIR = os.path.join(PROJECT_ROOT, \"checkpoints\", \"hrm\")\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "PROPERTIES = [\"Tg\", \"FFV\", \"Tc\", \"Density\", \"Rg\"]\n",
    "TARGET_DIM = len(PROPERTIES)\n",
    "\n",
    "# Trainingseinstellungen\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "CHECKPOINT_EVERY_N_STEPS = 100\n",
    "K_HEADS = 16  # Size of the KMeansCarry.mask feature dimension (only interface, not used here)\n",
    "\n",
    "# Optional: Limit the number of samples (None = all)\n",
    "MAX_SAMPLES = 5\n",
    "\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fac75a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 5\n",
      "Processing reached 1/5: *CC(*)c1ccccc1C(=O)OCCCCCC (17 atoms)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing reached 5/5: *Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N+](=O)[O-])cc3)c(C(*)=O)cc2OCCCCCCCCCOCC2CCCN2c2ccc([N+](=O)[O-])cc2)cc1 (70 atoms)\n",
      "\n",
      "Successfully extended: 24 molecules\n",
      "Failed extensions: 0\n",
      "example aux_info: [3 17 87\n",
      " 'CCCCCCOC(=O)c1ccccc1C(C)CC(CCC(CC(CC(C)c1ccccc1C(=O)OCCCCCC)c1ccccc1C(=O)OCCCCCC)c1ccccc1C(=O)OCCCCCC)c1ccccc1C(=O)OCCCCCC']\n",
      "Train graphs: 21 | Val graphs: 3\n",
      "Input dim: 6, Target dim: 5\n",
      "Edge dim: 4\n",
      "\n",
      "Examples of SMILES extensions:\n",
      "Original (17 atoms): *CC(*)c1ccccc1C(=O)OCCCCCC\n",
      "Extended (87 atoms): CCCCCCOC(=O)c1ccccc1C(C)CC(CCC(CC(CC(C)c1ccccc1C(=O)OCCCCCC)c1ccccc1C(=O)OCCCCCC)c1ccccc1C(=O)OCCCCCC)c1ccccc1C(=O)OCCCCCC\n",
      "\n",
      "Original (42 atoms): *Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)c(-c3ccc(C)cc3)c2-c2ccc(C)cc2)cc1\n",
      "Extended (128 atoms): CNc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(NNc3c(-c4ccc(C)cc4)c(-c4ccc(C)cc4)c(-c4ccc(NNc5ccc(-c6c(-c7ccc(C)cc7)c(-c7ccc(C)cc7)c(NC)c(-c7ccc(C)cc7)c6-c6ccc(C)cc6)cc5)cc4)c(-c4ccc(C)cc4)c3-c3ccc(C)cc3)c(-c3ccc(C)cc3)c2-c2ccc(C)cc2)cc1\n",
      "\n",
      "Original (17 atoms): *CC(*)c1ccccc1C(=O)OCCCCCC\n",
      "Extended (36 atoms): CCCCCCOC(=O)c1ccccc1C(C)CCC(C)c1ccccc1C(=O)OCCCCCC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset_helpers import smiles_iter_to_graph_dataset\n",
    "from data_gen_helpers import iterative_extend_smiles, count_non_hydrogen_atoms\n",
    "from data_gen_helpers import logger as data_gen_logger\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "data_gen_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger(\"main\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.FileHandler(f\"main_{datetime.now().strftime('%Y%m%d%H%M%S')}.log\", mode=\"a\")\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)\n",
    "data_gen_logger.addHandler(handler)\n",
    "\n",
    "\n",
    "# Load data\n",
    "VAL_RATIO = 0.1\n",
    "\n",
    "# Load CSV\n",
    "raw_df = pd.read_csv(DATA_CSV)\n",
    "raw_df = raw_df[[\"SMILES\"] + PROPERTIES].dropna(subset=[\"SMILES\"])\n",
    "if MAX_SAMPLES is not None:\n",
    "    raw_df = raw_df.iloc[:MAX_SAMPLES].reset_index(drop=True)\n",
    "\n",
    "print(f\"Original dataset size: {len(raw_df)}\")\n",
    "\n",
    "# Extend SMILES to reach at least 25 atoms (excluding hydrogen)\n",
    "extended_data = []\n",
    "failed_extensions = []\n",
    "\n",
    "for idx, row in raw_df.iterrows():\n",
    "    original_smiles = row[\"SMILES\"]\n",
    "    original_atoms = count_non_hydrogen_atoms(original_smiles)\n",
    "    \n",
    "    if idx % 50 == 0 or idx == len(raw_df) - 1:\n",
    "        print(f\"Processing reached {idx+1}/{len(raw_df)}: {original_smiles} ({original_atoms} atoms)\")\n",
    "    \n",
    "    try:\n",
    "        # Generate extended SMILES with at least 100 atoms (realistic value)\n",
    "        extensions = list(iterative_extend_smiles(\n",
    "            original_smiles, \n",
    "            min_length=100, \n",
    "            max_output=10,  # 10 variants\n",
    "        ))\n",
    "        \n",
    "        if extensions:\n",
    "            # Use the first successful extension\n",
    "            for extended_smiles, monomer_count in extensions:\n",
    "                final_atoms = count_non_hydrogen_atoms(extended_smiles)\n",
    "                \n",
    "                # Create new row with extended SMILES\n",
    "                new_row = row.copy()\n",
    "                new_row[\"SMILES\"] = extended_smiles\n",
    "                new_row[\"monomer_count\"] = monomer_count\n",
    "                new_row[\"original_smiles\"] = original_smiles\n",
    "                new_row[\"original_atoms\"] = original_atoms\n",
    "                new_row[\"final_atoms\"] = final_atoms\n",
    "                extended_data.append(new_row)\n",
    "            logger.debug(f\"  -> Success: {len(extensions)} molecules for {original_smiles} ({final_atoms} atoms)\")\n",
    "        else:\n",
    "            failed_extensions.append((idx, original_smiles, \"No extensions generated\"))\n",
    "            logger.debug(f\"  -> Failed: No extensions generated\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        failed_extensions.append((idx, original_smiles, str(e)))\n",
    "        logger.debug(f\"  -> Failed: {e}\")\n",
    "\n",
    "AUX_INFO = [\"monomer_count\", \"original_atoms\", \"final_atoms\", \"SMILES\"]\n",
    "\n",
    "# Create new DataFrame with extended SMILES\n",
    "extended_df = pd.DataFrame(extended_data)\n",
    "print(f\"\\nSuccessfully extended: {len(extended_df)} molecules\")\n",
    "print(f\"Failed extensions: {len(failed_extensions)}\")\n",
    "\n",
    "if len(failed_extensions) > 0:\n",
    "    logger.debug(\"\\n\\nFailed molecules:\\n\\n\")\n",
    "    for idx, smiles, error in failed_extensions:  # Show first 5 errors\n",
    "        logger.debug(f\"  {idx}: {smiles} - {error}\")\n",
    "\n",
    "# Use extended data for training\n",
    "if len(extended_df) == 0:\n",
    "    raise RuntimeError(\"No molecules could be extended. Check your data and extension logic.\")\n",
    "\n",
    "# Split into Train/Val\n",
    "num_rows = len(extended_df)\n",
    "perm = np.random.RandomState(SEED).permutation(num_rows)\n",
    "train_count = int((1.0 - VAL_RATIO) * num_rows)\n",
    "train_idx, val_idx = perm[:train_count], perm[train_count:]\n",
    "train_df = extended_df.iloc[train_idx].reset_index(drop=True)\n",
    "val_df = extended_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "# Create graph datasets\n",
    "train_dataset = smiles_iter_to_graph_dataset(train_df[\"SMILES\"], torch.tensor(train_df[PROPERTIES].to_numpy(), dtype=torch.float32, device=device), aux_info=train_df[AUX_INFO])\n",
    "val_dataset = smiles_iter_to_graph_dataset(val_df[\"SMILES\"], torch.tensor(val_df[PROPERTIES].to_numpy(), dtype=torch.float32, device=device), aux_info=val_df[AUX_INFO])\n",
    "\n",
    "print(f\"example aux_info: {train_dataset[0].aux_info}\")\n",
    "print(f\"Train graphs: {len(train_dataset)} | Val graphs: {len(val_dataset)}\")\n",
    "\n",
    "# DataListLoader (batched lists of Data objects)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Derive input dimension from first training graph\n",
    "if len(train_dataset) == 0:\n",
    "    raise RuntimeError(\"Training dataset is empty after preprocessing.\")\n",
    "INPUT_DIM = train_dataset[0].x.shape[1]\n",
    "print(f\"Input dim: {INPUT_DIM}, Target dim: {TARGET_DIM}\")\n",
    "\n",
    "EDGE_DIM = train_dataset[0].edge_attr.shape[1]\n",
    "print(f\"Edge dim: {EDGE_DIM}\")\n",
    "\n",
    "# Show some examples of the extensions\n",
    "print(f\"\\nExamples of SMILES extensions:\")\n",
    "for i in range(min(3, len(train_df))):\n",
    "    row = train_df.iloc[i]\n",
    "    print(f\"Original ({row.get('original_atoms', 'N/A')} atoms): {row.get('original_smiles', 'N/A')}\")\n",
    "    print(f\"Extended ({row.get('final_atoms', 'N/A')} atoms): {row['SMILES']}\")\n",
    "    print()\n",
    "\n",
    "TOTAL_BATCH_COUNT = len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "42fea702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeansHRMModule created with 7,378 trainable parameters\n",
      "Model size: 0.03 MB (float32)\n",
      "KMeansHRMModule(\n",
      "  (inner_module): KMeansHRMInnerModule(\n",
      "    (kmeans_module): KMeans(\n",
      "      (heads): ModuleList(\n",
      "        (0-1): 2 x KMeansHead(\n",
      "          (weighting_module): SpectralWeighting(\n",
      "            (cheb_convs): ModuleList(\n",
      "              (0-1): 2 x ChebConv(4, 4, K=3, normalization=sym)\n",
      "            )\n",
      "            (norms): ModuleList(\n",
      "              (0-1): 2 x BatchNorm(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (center_module): DiscreteMeanCenter(\n",
      "            (distance_module): PairwiseDistance()\n",
      "          )\n",
      "          (mask_module): RadiusAttentionWeights(\n",
      "            (weighting_module): GATConv(4, 4, heads=1)\n",
      "            (_mask_linear): Linear(in_features=4, out_features=1, bias=True)\n",
      "          )\n",
      "          (act): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (vgae_encoder): VGAEEncoder(\n",
      "      (norms): ModuleList(\n",
      "        (0-14): 15 x LayerNorm(16, affine=True, mode=graph)\n",
      "      )\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConv(4, 16)\n",
      "        (1-14): 14 x GCNConv(16, 16)\n",
      "        (15): GCNConv(16, 4)\n",
      "      )\n",
      "      (edge_attr_linear): Linear(in_features=4, out_features=1, bias=True)\n",
      "    )\n",
      "    (vgae): VGAE(\n",
      "      (encoder): VGAEEncoder(\n",
      "        (norms): ModuleList(\n",
      "          (0-14): 15 x LayerNorm(16, affine=True, mode=graph)\n",
      "        )\n",
      "        (convs): ModuleList(\n",
      "          (0): GCNConv(4, 16)\n",
      "          (1-14): 14 x GCNConv(16, 16)\n",
      "          (15): GCNConv(16, 4)\n",
      "        )\n",
      "        (edge_attr_linear): Linear(in_features=4, out_features=1, bias=True)\n",
      "      )\n",
      "      (decoder): InnerProductDecoder()\n",
      "    )\n",
      "    (linear_post_attention): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "      (3): Linear(in_features=32, out_features=4, bias=True)\n",
      "      (4): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (norm): LayerNorm(4, affine=True, mode=graph)\n",
      "    (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "    (output_head): OutputHead(\n",
      "      (linear1): Linear(4, 4, bias=True)\n",
      "      (linear2): Linear(4, 5, bias=True)\n",
      "      (norm): BatchNorm(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (policy_module): OutputHead(\n",
      "      (linear1): Linear(4, 2, bias=True)\n",
      "      (linear2): Linear(2, 2, bias=True)\n",
      "      (norm): BatchNorm(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pre_encoder_conv): NNConv(6, 6, aggr=mean, nn=Sequential(\n",
      "    (0): Linear(in_features=4, out_features=24, bias=True)\n",
      "    (1): Linear(in_features=24, out_features=24, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Linear(in_features=24, out_features=24, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.1, inplace=False)\n",
      "    (7): Linear(in_features=24, out_features=36, bias=True)\n",
      "  ))\n",
      "  (vgae_encoder): VGAEEncoder(\n",
      "    (norms): ModuleList(\n",
      "      (0): LayerNorm(4, affine=True, mode=graph)\n",
      "    )\n",
      "    (convs): ModuleList(\n",
      "      (0): ChebConv(6, 4, K=3, normalization=sym)\n",
      "      (1): ChebConv(4, 4, K=3, normalization=sym)\n",
      "    )\n",
      "    (edge_attr_linear): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "  (vgae): VGAE(\n",
      "    (encoder): VGAEEncoder(\n",
      "      (norms): ModuleList(\n",
      "        (0): LayerNorm(4, affine=True, mode=graph)\n",
      "      )\n",
      "      (convs): ModuleList(\n",
      "        (0): ChebConv(6, 4, K=3, normalization=sym)\n",
      "        (1): ChebConv(4, 4, K=3, normalization=sym)\n",
      "      )\n",
      "      (edge_attr_linear): Linear(in_features=4, out_features=1, bias=True)\n",
      "    )\n",
      "    (decoder): InnerProductDecoder()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Use KMeansHRMModule from kmeans_hrm_model.py\n",
    "from kmeans_hrm_model import (\n",
    "    KMeansHRMModule, KMeansHRMConfig, KMeansHRMInnerModuleConfig, KMeansHRMInitialCarry,\n",
    "    KMeansConfig, KMeansHeadConfig, OutputHeadConfig,\n",
    "    SpectralWeighting, SpectralWeightingConfig,\n",
    "    DiscreteMeanCenter, DiscreteMeanCenterConfig,\n",
    "    RadiusAttentionWeights, RadiusMaskConfig\n",
    ")\n",
    "\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Anzahl der trainierbaren Parameter im Modell zählen\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def create_kmeans_hrm_config(input_dim: int, edge_dim: int, hidden_dim: int = 128, latent_dim: int = 128, output_dim: int = TARGET_DIM, k: int = K_HEADS) -> KMeansHRMConfig:\n",
    "    \n",
    "    # Spectral Weighting Configuration\n",
    "    spectral_config = SpectralWeightingConfig(\n",
    "        node_channels=latent_dim,\n",
    "        K=3,  # Chebyshev polynomial order\n",
    "        num_layers=2,\n",
    "        normalization='sym',\n",
    "        bias=True,\n",
    "        dropout=0.2,\n",
    "        norm='batch',\n",
    "        norm_kwargs={'in_channels': latent_dim}\n",
    "    )\n",
    "    \n",
    "    # Center Module Configuration\n",
    "    center_config = DiscreteMeanCenterConfig(\n",
    "        distance_metric='euclidean'\n",
    "    )\n",
    "    \n",
    "    # Radius Mask Configuration (simplified weighting module)\n",
    "    radius_weighting = GATConv(latent_dim, latent_dim)\n",
    "    radius_config = RadiusMaskConfig(\n",
    "        max_num_neighbors=25,\n",
    "        radius=20,\n",
    "        weighting_module=radius_weighting,\n",
    "        threshold=0.1,\n",
    "        node_dim=latent_dim\n",
    "    )\n",
    "    \n",
    "    # KMeans Head Configuration\n",
    "    kmeans_head_config = KMeansHeadConfig(\n",
    "        node_count=k,\n",
    "        node_dim=latent_dim,\n",
    "        max_nodes=100,  \n",
    "        num_layers=5,\n",
    "        dropout=0.2,\n",
    "        weighting_module=SpectralWeighting(spectral_config),\n",
    "        center_module=DiscreteMeanCenter(center_config),\n",
    "        mask_module=RadiusAttentionWeights(radius_config),\n",
    "        act='relu',\n",
    "        act_kwargs={}\n",
    "    )\n",
    "    \n",
    "    # KMeans Configuration\n",
    "    kmeans_config = KMeansConfig(\n",
    "        k=k,\n",
    "        max_iter=10,\n",
    "        thresh=1e-6,\n",
    "        max_overlap=2,\n",
    "        head_module=kmeans_head_config,\n",
    "        excluded_is_cluster=True\n",
    "    )\n",
    "    \n",
    "    # Output Head Configuration\n",
    "    output_head_config = OutputHeadConfig(\n",
    "        node_dim=latent_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        output_dim=output_dim,\n",
    "        pooling_type='mean',\n",
    "        norm='batch',\n",
    "        norm_kwargs={'in_channels': hidden_dim},\n",
    "        act='relu',\n",
    "        act_kwargs={}\n",
    "    )\n",
    "    \n",
    "    # Policy Module Configuration (für Halt-Entscheidungen)\n",
    "    policy_config = OutputHeadConfig(\n",
    "        node_dim=latent_dim,\n",
    "        hidden_dim=hidden_dim//2,\n",
    "        output_dim=2,  # halt=0, continue=1\n",
    "        pooling_type='mean',\n",
    "        norm='batch',\n",
    "        norm_kwargs={'in_channels': hidden_dim//2},\n",
    "        act='relu',\n",
    "        act_kwargs={}\n",
    "    )\n",
    "    \n",
    "    # Inner Module Configuration\n",
    "    inner_config = KMeansHRMInnerModuleConfig(\n",
    "        add_self_loops=True,\n",
    "        add_negative_edges=True,\n",
    "        dropout=0.2,\n",
    "        hidden_dim=hidden_dim,        # inner-side hidden size, reused\n",
    "        node_dim=latent_dim,          # must equal vgae_latent_dim\n",
    "        attention_dim=16,           # bigger in final\n",
    "        edge_dim=edge_dim,\n",
    "        layers=3,\n",
    "        kmeans_config=kmeans_config,\n",
    "        output_head_config=output_head_config,\n",
    "        policy_module_config=policy_config,\n",
    "        K_cycles=2,\n",
    "        L_cycles=2,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        halt_max_steps=5,\n",
    "        halt_exploration_prob=0.1,\n",
    "    )\n",
    "    \n",
    "    # Hauptkonfiguration\n",
    "    config = KMeansHRMConfig(\n",
    "        inner_module=inner_config,\n",
    "        explore_steps_prob=0.1,\n",
    "        halt_max_steps=5,\n",
    "        pre_encoder_conv_layers=2,\n",
    "        vgae_encoder_type=\"cheb\",\n",
    "        input_dim=input_dim,\n",
    "        edge_attr_dim=edge_dim,\n",
    "        vgae_latent_dim=latent_dim,           # must equal inner.node_dim\n",
    "        vgae_encoder_layers=2,\n",
    "        vgae_encoder_dropout=0.1,\n",
    "        vgae_decoder_type=None,\n",
    "        vgae_kl_weight=1.0,\n",
    "    )\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Modell initialisieren\n",
    "hrm_config = create_kmeans_hrm_config(INPUT_DIM, EDGE_DIM, latent_dim=4, hidden_dim=4, output_dim=TARGET_DIM, k=2)\n",
    "model = KMeansHRMModule(hrm_config, training=True).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Print number of parameters\n",
    "num_params = count_parameters(model)\n",
    "print(f\"KMeansHRMModule created with {num_params:,} trainable parameters\")\n",
    "print(f\"Model size: {num_params * 4 / 1024 / 1024:.2f} MB (float32)\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7e6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss and metrics initialized.\n"
     ]
    }
   ],
   "source": [
    "# Loss: Range-violation for missing, otherwise MSE\n",
    "# Note: HRM-repo inspiration (loss splitting, early checkpoints), see links below\n",
    "# - losses.py and pretrain.py from HRM (only as idea source)\n",
    "import numpy as np\n",
    "from typing import Union, List\n",
    "from training_loops import composite_loss, compute_mae_in_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d87fb36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing new carry for batch 1812\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 902 is out of bounds for dimension 0 with size 491",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[111]\u001b[39m\u001b[32m, line 181\u001b[39m\n\u001b[32m    178\u001b[39m count_samples = \u001b[32m0\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     metrics = \u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m     batch_size_effective = batch_data.num_graphs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(batch_data, \u001b[33m'\u001b[39m\u001b[33mnum_graphs\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m BATCH_SIZE\n\u001b[32m    184\u001b[39m     running_loss += metrics[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m] * batch_size_effective\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[111]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mtrain_batch\u001b[39m\u001b[34m(epoch, train_state, batch_data, config)\u001b[39m\n\u001b[32m     73\u001b[39m     train_state.carry = model.initial_carry(batch_data)\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m train_state.carry, hrm_output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcarry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m preds = hrm_output[\u001b[33m'\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     79\u001b[39m loss = composite_loss(preds, y, related_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/chem-properties/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/chem-properties/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/chem-properties/src/kmeans_hrm_model.py:19\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, carry, data)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Batch, Data\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     ChebConv,\n\u001b[32m     13\u001b[39m     GATConv,\n\u001b[32m     14\u001b[39m     GCNConv,\n\u001b[32m     15\u001b[39m     GlobalAttention,\n\u001b[32m     16\u001b[39m     InnerProductDecoder,\n\u001b[32m     17\u001b[39m     LayerNorm,\n\u001b[32m     18\u001b[39m     NNConv,\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     MessagePassing,\n\u001b[32m     20\u001b[39m     VGAE,\n\u001b[32m     21\u001b[39m     global_add_pool,\n\u001b[32m     22\u001b[39m     global_max_pool,\n\u001b[32m     23\u001b[39m     global_mean_pool,\n\u001b[32m     24\u001b[39m     Linear\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m radius\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresolver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activation_resolver, normalization_resolver\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/chem-properties/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/chem-properties/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/chem-properties/src/kmeans_hrm_model.py:19\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, kmeans_carry, inputs, batch)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Batch, Data\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     ChebConv,\n\u001b[32m     13\u001b[39m     GATConv,\n\u001b[32m     14\u001b[39m     GCNConv,\n\u001b[32m     15\u001b[39m     GlobalAttention,\n\u001b[32m     16\u001b[39m     InnerProductDecoder,\n\u001b[32m     17\u001b[39m     LayerNorm,\n\u001b[32m     18\u001b[39m     NNConv,\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     MessagePassing,\n\u001b[32m     20\u001b[39m     VGAE,\n\u001b[32m     21\u001b[39m     global_add_pool,\n\u001b[32m     22\u001b[39m     global_max_pool,\n\u001b[32m     23\u001b[39m     global_mean_pool,\n\u001b[32m     24\u001b[39m     Linear\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m radius\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresolver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activation_resolver, normalization_resolver\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/chem-properties/src/kmeans_hrm_model.py:21\u001b[39m, in \u001b[36m_forward_per_graph\u001b[39m\u001b[34m(self, kmeans_carry, inputs, batch)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Batch, Data\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     ChebConv,\n\u001b[32m     13\u001b[39m     GATConv,\n\u001b[32m     14\u001b[39m     GCNConv,\n\u001b[32m     15\u001b[39m     GlobalAttention,\n\u001b[32m     16\u001b[39m     InnerProductDecoder,\n\u001b[32m     17\u001b[39m     LayerNorm,\n\u001b[32m     18\u001b[39m     NNConv,\n\u001b[32m     19\u001b[39m     MessagePassing,\n\u001b[32m     20\u001b[39m     VGAE,\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     global_add_pool,\n\u001b[32m     22\u001b[39m     global_max_pool,\n\u001b[32m     23\u001b[39m     global_mean_pool,\n\u001b[32m     24\u001b[39m     Linear\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m radius\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresolver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activation_resolver, normalization_resolver\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/chem-properties/src/kmeans_hrm_model.py:10\u001b[39m, in \u001b[36mmasked_edge_index\u001b[39m\u001b[34m(self, mask_idx)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Batch, Data\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     ChebConv,\n\u001b[32m     13\u001b[39m     GATConv,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     Linear\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m radius\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/chem-properties/.venv/lib/python3.11/site-packages/torch_geometric/utils/_subgraph.py:143\u001b[39m, in \u001b[36msubgraph\u001b[39m\u001b[34m(subset, edge_index, edge_attr, relabel_nodes, num_nodes, return_edge_mask)\u001b[39m\n\u001b[32m    140\u001b[39m     node_mask = subset\n\u001b[32m    141\u001b[39m     subset = node_mask.nonzero().view(-\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m edge_mask = \u001b[43mnode_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m & node_mask[edge_index[\u001b[32m1\u001b[39m]]\n\u001b[32m    144\u001b[39m edge_index = edge_index[:, edge_mask]\n\u001b[32m    145\u001b[39m edge_attr = edge_attr[edge_mask] \u001b[38;5;28;01mif\u001b[39;00m edge_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: index 902 is out of bounds for dimension 0 with size 491"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "def save_checkpoint(state: Dict, step: int, is_best: bool = False):\n",
    "    path = os.path.join(CHECKPOINT_DIR, f\"step_{step}.pt\")\n",
    "    torch.save(state, path)\n",
    "    if is_best:\n",
    "        best_path = os.path.join(CHECKPOINT_DIR, \"best.pt\")\n",
    "        torch.save(state, best_path)\n",
    "\n",
    "\n",
    "class PretrainConfig(TypedDict):\n",
    "    # Data\n",
    "    data_path: str\n",
    "\n",
    "    # Hyperparams\n",
    "    global_batch_size: int\n",
    "    epochs: int\n",
    "    total_iters: int\n",
    "\n",
    "    lr: float\n",
    "    lr_min_ratio: float\n",
    "    lr_warmup_steps: int\n",
    "\n",
    "    weight_decay: float\n",
    "    beta1: float\n",
    "    beta2: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainState:\n",
    "    model: nn.Module\n",
    "    optimizer: torch.optim.Optimizer\n",
    "    carry: KMeansHRMInitialCarry | None\n",
    "\n",
    "    step: int\n",
    "    total_steps: int\n",
    "\n",
    "\n",
    "def compute_warmup_weight(step: int, warmup_steps: int, min_ratio: float) -> float:\n",
    "    if warmup_steps <= 0:\n",
    "        return 1.0\n",
    "    if step < warmup_steps:\n",
    "        # Linear warmup from min_ratio -> 1.0\n",
    "        return float(min_ratio + (1.0 - min_ratio) * (step / max(1, warmup_steps)))\n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def pack_train_state_for_save(ts: TrainState) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"step\": int(ts.step),\n",
    "        \"total_steps\": int(ts.total_steps),\n",
    "        # Carry can be large; still useful for exact resume within the same batch sequence\n",
    "        \"carry\": ts.carry,\n",
    "    }\n",
    "\n",
    "\n",
    "def train_batch(epoch: int, train_state: TrainState, batch_data: Batch, config: PretrainConfig) -> Dict[str, float]:\n",
    "    model = train_state.model\n",
    "    optimizer = train_state.optimizer\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Targets [B,5]\n",
    "    y = torch.stack([g.y for g in batch_data.to_data_list()], dim=0).to(device)\n",
    "    batch_data = batch_data.to(device)\n",
    "    related_info = batch_data.aux_info\n",
    "\n",
    "    # Reuse existing carry if provided; otherwise initialize\n",
    "    if train_state.carry is None:\n",
    "        print(f\"Initializing new carry for batch {batch_data.batch.shape[0]}\")\n",
    "        train_state.carry = model.initial_carry(batch_data)\n",
    "\n",
    "    # Forward\n",
    "    train_state.carry, hrm_output = model(train_state.carry, batch_data)\n",
    "    preds = hrm_output['y_pred']\n",
    "\n",
    "    loss = composite_loss(preds, y, related_info)\n",
    "    train_state.step += 1\n",
    "    warmup_w = compute_warmup_weight(train_state.step, config[\"lr_warmup_steps\"], config[\"lr_min_ratio\"])  # type: ignore[index]\n",
    "    scaled_loss = loss * warmup_w * (1.0 / TOTAL_BATCH_COUNT)\n",
    "\n",
    "    # Backward/update\n",
    "    optimizer.zero_grad()\n",
    "    scaled_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Metrics (unscaled loss for logging)\n",
    "    with torch.no_grad():\n",
    "        metrics = compute_mae_in_bounds(preds, y, related_info)\n",
    "        metrics.update({\n",
    "            \"loss\": loss.item(),\n",
    "            \"warmup_weight\": float(warmup_w),\n",
    "        })\n",
    "\n",
    "\n",
    "    # Periodic checkpoint\n",
    "    global_step = train_state.step\n",
    "    if global_step % CHECKPOINT_EVERY_N_STEPS == 0:\n",
    "        save_checkpoint({\n",
    "            \"epoch\": epoch,\n",
    "            \"global_step\": global_step,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"model_class\": model.__class__.__name__,\n",
    "            \"model_module\": model.__class__.__module__,\n",
    "            \"train_state\": pack_train_state_for_save(train_state),\n",
    "        }, step=global_step)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(epoch: int, model: nn.Module, loader: DataLoader) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    mae_accum = {f\"mae_{p}\": 0.0 for p in PROPERTIES}\n",
    "    count_samples = 0\n",
    "\n",
    "    for batch_data in loader:\n",
    "        y = torch.stack([g.y for g in batch_data.to_data_list()], dim=0).to(device)\n",
    "        batch_data = batch_data.to(device)\n",
    "        related_info = batch_data.aux_info\n",
    "        \n",
    "        carry = model.initial_carry(batch_data)\n",
    "        _, hrm_output = model(carry, batch_data)\n",
    "        preds = hrm_output['y_pred']\n",
    "\n",
    "        loss = composite_loss(preds, y, related_info)\n",
    "\n",
    "        metrics = compute_mae_in_bounds(preds, y, related_info)\n",
    "        for k, v in metrics.items():\n",
    "            if not math.isnan(v):\n",
    "                mae_accum[k] += v * preds.size(0)\n",
    "        running_loss += loss.item() * preds.size(0)\n",
    "        count_samples += preds.size(0)\n",
    "\n",
    "    avg_loss = running_loss / max(1, count_samples)\n",
    "    avg_mae = {k: (v / max(1, count_samples)) for k, v in mae_accum.items()}\n",
    "\n",
    "    return {\"loss\": avg_loss, **avg_mae}\n",
    "\n",
    "\n",
    "# Build a minimal config for warmup from existing hyperparams\n",
    "CONFIG: PretrainConfig = {\n",
    "    \"data_path\": DATA_CSV,\n",
    "    \"global_batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    # Step-based training support; used by helper loop\n",
    "    \"total_iters\": int(EPOCHS * len(train_loader)),\n",
    "    \"lr\": LR,\n",
    "    \"lr_min_ratio\": 0.1,\n",
    "    \"lr_warmup_steps\": max(1, len(train_loader) * 2),  # warm up first ~2 epochs of steps\n",
    "    \"weight_decay\": WEIGHT_DECAY,\n",
    "    \"beta1\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "}\n",
    "\n",
    "\n",
    "history = {\"train\": [], \"val\": []}\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "# Initialize TrainState with total steps estimated from loader length and epochs\n",
    "train_state = TrainState(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    carry=None,\n",
    "    step=0,\n",
    "    total_steps=CONFIG[\"epochs\"] * len(train_loader)\n",
    ")\n",
    "\n",
    "for epoch in range(1, CONFIG[\"epochs\"] + 1):\n",
    "    # Accumulators for epoch\n",
    "    running_loss = 0.0\n",
    "    mae_accum = {f\"mae_{p}\": 0.0 for p in PROPERTIES}\n",
    "    count_samples = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        metrics = train_batch(epoch, train_state, batch_data, CONFIG)\n",
    "        batch_size_effective = batch_data.num_graphs if hasattr(batch_data, 'num_graphs') else BATCH_SIZE\n",
    "\n",
    "        running_loss += metrics[\"loss\"] * batch_size_effective\n",
    "        for k in list(mae_accum.keys()):\n",
    "            prop_name = k.split(\"mae_\")[-1]\n",
    "            if f\"mae_{prop_name}\" in metrics and not math.isnan(metrics[f\"mae_{prop_name}\"]):\n",
    "                mae_accum[k] += metrics[f\"mae_{prop_name}\"] * batch_size_effective\n",
    "        count_samples += batch_size_effective\n",
    "\n",
    "    train_stats = {\n",
    "        \"loss\": running_loss / max(1, count_samples),\n",
    "        **{k: (v / max(1, count_samples)) for k, v in mae_accum.items()},\n",
    "    }\n",
    "\n",
    "    val_stats = validate(epoch, train_state.model, val_loader)\n",
    "\n",
    "    history[\"train\"].append({\"epoch\": epoch, **train_stats})\n",
    "    history[\"val\"].append({\"epoch\": epoch, **val_stats})\n",
    "\n",
    "    is_best = val_stats[\"loss\"] < best_val_loss\n",
    "    if is_best:\n",
    "        best_val_loss = val_stats[\"loss\"]\n",
    "\n",
    "    save_checkpoint({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": train_state.model.state_dict(),\n",
    "        \"optimizer_state\": train_state.optimizer.state_dict(),\n",
    "        \"train_stats\": train_stats,\n",
    "        \"val_stats\": val_stats,\n",
    "        \"model_class\": train_state.model.__class__.__name__,\n",
    "        \"model_module\": train_state.model.__class__.__module__,\n",
    "        \"train_state\": pack_train_state_for_save(train_state),\n",
    "    }, step=epoch, is_best=is_best)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | train_loss={train_stats['loss']:.4f} | val_loss={val_stats['loss']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6d629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_loops import load_checkpoint\n",
    "import glob\n",
    "\n",
    "# Restore model/optimizer/train_state from a checkpoint (best.pt preferred)\n",
    "best_path = os.path.join(CHECKPOINT_DIR, \"best.pt\")\n",
    "chosen_path = None\n",
    "if os.path.isfile(best_path):\n",
    "    chosen_path = best_path\n",
    "else:\n",
    "    candidates = sorted(glob.glob(os.path.join(CHECKPOINT_DIR, \"step_*.pt\")))\n",
    "    if len(candidates) > 0:\n",
    "        # Choose the numerically largest step\n",
    "        def _step_num(p):\n",
    "            try:\n",
    "                base = os.path.basename(p)\n",
    "                num = int(base.replace(\"step_\", \"\").replace(\".pt\", \"\"))\n",
    "                return num\n",
    "            except Exception:\n",
    "                return -1\n",
    "        candidates.sort(key=_step_num)\n",
    "        chosen_path = candidates[-1]\n",
    "\n",
    "if chosen_path:\n",
    "    raw_state, saved_ts = load_checkpoint(chosen_path, model, optimizer, map_location=device)\n",
    "    if isinstance(saved_ts, dict):\n",
    "        try:\n",
    "            train_state.step = int(saved_ts.get(\"step\", train_state.step))\n",
    "            train_state.total_steps = int(saved_ts.get(\"total_steps\", train_state.total_steps))\n",
    "            train_state.carry = saved_ts.get(\"carry\", None)\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(f\"Loaded checkpoint: {chosen_path} | step={train_state.step}\")\n",
    "else:\n",
    "    print(\"No checkpoint found to load.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_loops import train_until_total_iters\n",
    "\n",
    "# If you want to override step budget, set CONFIG[\"total_iters\"] directly\n",
    "TOTAL_ITERS = int(CONFIG.get(\"total_iters\", EPOCHS * len(train_loader)))\n",
    "print(f\"Training until total_iters = {TOTAL_ITERS}\")\n",
    "\n",
    "# Run the total_iters-driven loop\n",
    "history_step, best_val_loss = train_until_total_iters(\n",
    "    total_iters=TOTAL_ITERS,\n",
    "    start_epoch=1,\n",
    "    train_state=train_state,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    config=CONFIG,\n",
    "    train_batch_fn=train_batch,\n",
    "    validate_fn=validate,\n",
    "    save_checkpoint_fn=save_checkpoint,\n",
    "    checkpoint_every_n=CHECKPOINT_EVERY_N_STEPS,\n",
    "    print_every_n=25,\n",
    ")\n",
    "\n",
    "# Merge history into the existing one for convenience\n",
    "history[\"train\"].extend(history_step[\"train\"])  # type: ignore[index]\n",
    "history[\"val\"].extend(history_step[\"val\"])      # type: ignore[index]\n",
    "print(f\"Done total_iters training. best_val_loss={best_val_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0b3b0f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metrics to /home/thomaspugh/projects/chem-properties/checkpoints/hrm/history.json\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "metrics_path = os.path.join(CHECKPOINT_DIR, \"history.json\")\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "print(f\"Saved metrics to {metrics_path}\")\n",
    "\n",
    "# Plot\n",
    "def plot_curves(history):\n",
    "    epochs = [e[\"epoch\"] for e in history[\"train\"]]\n",
    "    train_losses = [e[\"loss\"] for e in history[\"train\"]]\n",
    "    val_losses = [e[\"loss\"] for e in history[\"val\"]]\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(epochs, train_losses, label=\"train_loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"val_loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_curves(history)\n",
    "\n",
    "# Hinweis auf Quellen (Inspiration):\n",
    "# - HRM Losses und Training (nur als Anregung, nicht 1:1):\n",
    "#   https://github.com/sapientinc/HRM/blob/05dd4ef795a98c20110e380a330d0b3ec159a46b/models/losses.py\n",
    "#   https://github.com/sapientinc/HRM/blob/05dd4ef795a98c20110e380a330d0b3ec159a46b/pretrain.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
