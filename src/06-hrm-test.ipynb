{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ad503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696835c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                             SMILES  Tg       FFV  \\\n",
      "0   87817                         *CC(*)c1ccccc1C(=O)OCCCCCC NaN  0.374645   \n",
      "1  106919  *Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5... NaN  0.370410   \n",
      "2  388772  *Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(... NaN  0.378860   \n",
      "3  519416  *Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)... NaN  0.387324   \n",
      "4  539187  *Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N... NaN  0.355470   \n",
      "\n",
      "         Tc  Density  Rg  \n",
      "0  0.205667      NaN NaN  \n",
      "1       NaN      NaN NaN  \n",
      "2       NaN      NaN NaN  \n",
      "3       NaN      NaN NaN  \n",
      "4       NaN      NaN NaN  \n",
      "7973\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "full_train_data = pd.read_csv(\"../data/train.csv\")\n",
    "print(full_train_data.head())\n",
    "print(len(full_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2737b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "from typing import List, Tuple, Dict\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from kmeans_hrm_model import KMeansCarry\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Projektpfade und Trainingshyperparameter\n",
    "PROJECT_ROOT = \"/home/thomaspugh/projects/chem-properties\"\n",
    "DATA_CSV = os.path.join(PROJECT_ROOT, \"data\", \"train.csv\")\n",
    "CHECKPOINT_DIR = os.path.join(PROJECT_ROOT, \"checkpoints\", \"hrm\")\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "PROPERTIES = [\"Tg\", \"FFV\", \"Tc\", \"Density\", \"Rg\"]\n",
    "TARGET_DIM = len(PROPERTIES)\n",
    "\n",
    "# Trainingseinstellungen\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "CHECKPOINT_EVERY_N_STEPS = 100\n",
    "K_HEADS = 16  # Size of the KMeansCarry.mask feature dimension (only interface, not used here)\n",
    "\n",
    "# Optional: Limit the number of samples (None = all)\n",
    "MAX_SAMPLES = 5\n",
    "\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac75a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 5\n",
      "Processing reached 1/5: *CC(*)c1ccccc1C(=O)OCCCCCC (17 atoms)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n",
      "The SMILES writer does not write stereochemical information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing reached 5/5: *Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N+](=O)[O-])cc3)c(C(*)=O)cc2OCCCCCCCCCOCC2CCCN2c2ccc([N+](=O)[O-])cc2)cc1 (70 atoms)\n",
      "\n",
      "Successfully extended: 24 molecules\n",
      "Failed extensions: 0\n",
      "example aux_info: [3 17 87\n",
      " 'CCCCCCOC(=O)c1ccccc1C(C)CC(CCC(CC(CC(C)c1ccccc1C(=O)OCCCCCC)c1ccccc1C(=O)OCCCCCC)c1ccccc1C(=O)OCCCCCC)c1ccccc1C(=O)OCCCCCC']\n",
      "Train graphs: 21 | Val graphs: 3\n",
      "Input dim: 6, Target dim: 5\n",
      "Edge dim: 4\n",
      "\n",
      "Examples of SMILES extensions:\n",
      "Original (17 atoms): *CC(*)c1ccccc1C(=O)OCCCCCC\n",
      "Extended (87 atoms): CCCCCCOC(=O)c1ccccc1C(C)CC(CCC(CC(CC(C)c1ccccc1C(=O)OCCCCCC)c1ccccc1C(=O)OCCCCCC)c1ccccc1C(=O)OCCCCCC)c1ccccc1C(=O)OCCCCCC\n",
      "\n",
      "Original (42 atoms): *Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)c(-c3ccc(C)cc3)c2-c2ccc(C)cc2)cc1\n",
      "Extended (128 atoms): CNc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(NNc3c(-c4ccc(C)cc4)c(-c4ccc(C)cc4)c(-c4ccc(NNc5ccc(-c6c(-c7ccc(C)cc7)c(-c7ccc(C)cc7)c(NC)c(-c7ccc(C)cc7)c6-c6ccc(C)cc6)cc5)cc4)c(-c4ccc(C)cc4)c3-c3ccc(C)cc3)c(-c3ccc(C)cc3)c2-c2ccc(C)cc2)cc1\n",
      "\n",
      "Original (17 atoms): *CC(*)c1ccccc1C(=O)OCCCCCC\n",
      "Extended (36 atoms): CCCCCCOC(=O)c1ccccc1C(C)CCC(C)c1ccccc1C(=O)OCCCCCC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset_helpers import smiles_iter_to_graph_dataset\n",
    "from data_gen_helpers import iterative_extend_smiles, count_non_hydrogen_atoms\n",
    "from data_gen_helpers import logger as data_gen_logger\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "data_gen_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger(\"main\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.FileHandler(f\"main_{datetime.now().strftime('%Y%m%d%H%M%S')}.log\", mode=\"a\")\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)\n",
    "data_gen_logger.addHandler(handler)\n",
    "\n",
    "\n",
    "# Load data\n",
    "VAL_RATIO = 0.1\n",
    "\n",
    "# Load CSV\n",
    "raw_df = pd.read_csv(DATA_CSV)\n",
    "raw_df = raw_df[[\"SMILES\"] + PROPERTIES].dropna(subset=[\"SMILES\"])\n",
    "if MAX_SAMPLES is not None:\n",
    "    raw_df = raw_df.iloc[:MAX_SAMPLES].reset_index(drop=True)\n",
    "\n",
    "print(f\"Original dataset size: {len(raw_df)}\")\n",
    "\n",
    "# Extend SMILES to reach at least 25 atoms (excluding hydrogen)\n",
    "extended_data = []\n",
    "failed_extensions = []\n",
    "\n",
    "for idx, row in raw_df.iterrows():\n",
    "    original_smiles = row[\"SMILES\"]\n",
    "    original_atoms = count_non_hydrogen_atoms(original_smiles)\n",
    "    \n",
    "    if idx % 50 == 0 or idx == len(raw_df) - 1:\n",
    "        print(f\"Processing reached {idx+1}/{len(raw_df)}: {original_smiles} ({original_atoms} atoms)\")\n",
    "    \n",
    "    try:\n",
    "        # Generate extended SMILES with at least 100 atoms (realistic value)\n",
    "        extensions = list(iterative_extend_smiles(\n",
    "            original_smiles, \n",
    "            min_length=100, \n",
    "            max_output=10,  # 10 variants\n",
    "        ))\n",
    "        \n",
    "        if extensions:\n",
    "            # Use the first successful extension\n",
    "            for extended_smiles, monomer_count in extensions:\n",
    "                final_atoms = count_non_hydrogen_atoms(extended_smiles)\n",
    "                \n",
    "                # Create new row with extended SMILES\n",
    "                new_row = row.copy()\n",
    "                new_row[\"SMILES\"] = extended_smiles\n",
    "                new_row[\"monomer_count\"] = monomer_count\n",
    "                new_row[\"original_smiles\"] = original_smiles\n",
    "                new_row[\"original_atoms\"] = original_atoms\n",
    "                new_row[\"final_atoms\"] = final_atoms\n",
    "                extended_data.append(new_row)\n",
    "            logger.debug(f\"  -> Success: {len(extensions)} molecules for {original_smiles} ({final_atoms} atoms)\")\n",
    "        else:\n",
    "            failed_extensions.append((idx, original_smiles, \"No extensions generated\"))\n",
    "            logger.debug(f\"  -> Failed: No extensions generated\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        failed_extensions.append((idx, original_smiles, str(e)))\n",
    "        logger.debug(f\"  -> Failed: {e}\")\n",
    "\n",
    "AUX_INFO = [\"monomer_count\", \"original_atoms\", \"final_atoms\", \"SMILES\"]\n",
    "\n",
    "# Create new DataFrame with extended SMILES\n",
    "extended_df = pd.DataFrame(extended_data)\n",
    "print(f\"\\nSuccessfully extended: {len(extended_df)} molecules\")\n",
    "print(f\"Failed extensions: {len(failed_extensions)}\")\n",
    "\n",
    "if len(failed_extensions) > 0:\n",
    "    logger.debug(\"\\n\\nFailed molecules:\\n\\n\")\n",
    "    for idx, smiles, error in failed_extensions:  # Show first 5 errors\n",
    "        logger.debug(f\"  {idx}: {smiles} - {error}\")\n",
    "\n",
    "# Use extended data for training\n",
    "if len(extended_df) == 0:\n",
    "    raise RuntimeError(\"No molecules could be extended. Check your data and extension logic.\")\n",
    "\n",
    "# Split into Train/Val\n",
    "num_rows = len(extended_df)\n",
    "perm = np.random.RandomState(SEED).permutation(num_rows)\n",
    "train_count = int((1.0 - VAL_RATIO) * num_rows)\n",
    "train_idx, val_idx = perm[:train_count], perm[train_count:]\n",
    "train_df = extended_df.iloc[train_idx].reset_index(drop=True)\n",
    "val_df = extended_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "# Create graph datasets\n",
    "train_dataset = smiles_iter_to_graph_dataset(train_df[\"SMILES\"], torch.tensor(train_df[PROPERTIES].to_numpy(), dtype=torch.float32, device=device), aux_info=train_df[AUX_INFO])\n",
    "val_dataset = smiles_iter_to_graph_dataset(val_df[\"SMILES\"], torch.tensor(val_df[PROPERTIES].to_numpy(), dtype=torch.float32, device=device), aux_info=val_df[AUX_INFO])\n",
    "\n",
    "print(f\"example aux_info: {train_dataset[0].aux_info}\")\n",
    "print(f\"Train graphs: {len(train_dataset)} | Val graphs: {len(val_dataset)}\")\n",
    "\n",
    "# DataListLoader (batched lists of Data objects)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Derive input dimension from first training graph\n",
    "if len(train_dataset) == 0:\n",
    "    raise RuntimeError(\"Training dataset is empty after preprocessing.\")\n",
    "INPUT_DIM = train_dataset[0].x.shape[1]\n",
    "print(f\"Input dim: {INPUT_DIM}, Target dim: {TARGET_DIM}\")\n",
    "\n",
    "EDGE_DIM = train_dataset[0].edge_attr.shape[1]\n",
    "print(f\"Edge dim: {EDGE_DIM}\")\n",
    "\n",
    "# Show some examples of the extensions\n",
    "print(f\"\\nExamples of SMILES extensions:\")\n",
    "for i in range(min(3, len(train_df))):\n",
    "    row = train_df.iloc[i]\n",
    "    print(f\"Original ({row.get('original_atoms', 'N/A')} atoms): {row.get('original_smiles', 'N/A')}\")\n",
    "    print(f\"Extended ({row.get('final_atoms', 'N/A')} atoms): {row['SMILES']}\")\n",
    "    print()\n",
    "\n",
    "TOTAL_BATCH_COUNT = len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42fea702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeansHRMModule created with 7,378 trainable parameters\n",
      "Model size: 0.03 MB (float32)\n",
      "KMeansHRMModule(\n",
      "  (inner_module): KMeansHRMInnerModule(\n",
      "    (kmeans_module): KMeans(\n",
      "      (heads): ModuleList(\n",
      "        (0-1): 2 x KMeansHead(\n",
      "          (weighting_module): SpectralWeighting(\n",
      "            (cheb_convs): ModuleList(\n",
      "              (0-1): 2 x ChebConv(4, 4, K=3, normalization=sym)\n",
      "            )\n",
      "            (norms): ModuleList(\n",
      "              (0-1): 2 x BatchNorm(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (center_module): DiscreteMeanCenter(\n",
      "            (distance_module): PairwiseDistance()\n",
      "          )\n",
      "          (mask_module): RadiusAttentionWeights(\n",
      "            (weighting_module): GATConv(4, 4, heads=1)\n",
      "            (_mask_linear): Linear(in_features=4, out_features=1, bias=True)\n",
      "          )\n",
      "          (act): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (vgae_encoder): VGAEEncoder(\n",
      "      (norms): ModuleList(\n",
      "        (0-14): 15 x LayerNorm(16, affine=True, mode=graph)\n",
      "      )\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConv(4, 16)\n",
      "        (1-14): 14 x GCNConv(16, 16)\n",
      "        (15): GCNConv(16, 4)\n",
      "      )\n",
      "      (edge_attr_linear): Linear(in_features=4, out_features=1, bias=True)\n",
      "    )\n",
      "    (vgae): VGAE(\n",
      "      (encoder): VGAEEncoder(\n",
      "        (norms): ModuleList(\n",
      "          (0-14): 15 x LayerNorm(16, affine=True, mode=graph)\n",
      "        )\n",
      "        (convs): ModuleList(\n",
      "          (0): GCNConv(4, 16)\n",
      "          (1-14): 14 x GCNConv(16, 16)\n",
      "          (15): GCNConv(16, 4)\n",
      "        )\n",
      "        (edge_attr_linear): Linear(in_features=4, out_features=1, bias=True)\n",
      "      )\n",
      "      (decoder): InnerProductDecoder()\n",
      "    )\n",
      "    (linear_post_attention): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "      (3): Linear(in_features=32, out_features=4, bias=True)\n",
      "      (4): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (norm): LayerNorm(4, affine=True, mode=graph)\n",
      "    (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "    (output_head): OutputHead(\n",
      "      (linear1): Linear(4, 4, bias=True)\n",
      "      (linear2): Linear(4, 5, bias=True)\n",
      "      (norm): BatchNorm(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (policy_module): OutputHead(\n",
      "      (linear1): Linear(4, 2, bias=True)\n",
      "      (linear2): Linear(2, 2, bias=True)\n",
      "      (norm): BatchNorm(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pre_encoder_conv): NNConv(6, 6, aggr=mean, nn=Sequential(\n",
      "    (0): Linear(in_features=4, out_features=24, bias=True)\n",
      "    (1): Linear(in_features=24, out_features=24, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Linear(in_features=24, out_features=24, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.1, inplace=False)\n",
      "    (7): Linear(in_features=24, out_features=36, bias=True)\n",
      "  ))\n",
      "  (vgae_encoder): VGAEEncoder(\n",
      "    (norms): ModuleList(\n",
      "      (0): LayerNorm(4, affine=True, mode=graph)\n",
      "    )\n",
      "    (convs): ModuleList(\n",
      "      (0): ChebConv(6, 4, K=3, normalization=sym)\n",
      "      (1): ChebConv(4, 4, K=3, normalization=sym)\n",
      "    )\n",
      "    (edge_attr_linear): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "  (vgae): VGAE(\n",
      "    (encoder): VGAEEncoder(\n",
      "      (norms): ModuleList(\n",
      "        (0): LayerNorm(4, affine=True, mode=graph)\n",
      "      )\n",
      "      (convs): ModuleList(\n",
      "        (0): ChebConv(6, 4, K=3, normalization=sym)\n",
      "        (1): ChebConv(4, 4, K=3, normalization=sym)\n",
      "      )\n",
      "      (edge_attr_linear): Linear(in_features=4, out_features=1, bias=True)\n",
      "    )\n",
      "    (decoder): InnerProductDecoder()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Use KMeansHRMModule from kmeans_hrm_model.py\n",
    "from kmeans_hrm_model import (\n",
    "    KMeansHRMModule, KMeansHRMConfig, KMeansHRMInnerModuleConfig, KMeansHRMInitialCarry,\n",
    "    KMeansConfig, KMeansHeadConfig, OutputHeadConfig,\n",
    "    SpectralWeighting, SpectralWeightingConfig,\n",
    "    DiscreteMeanCenter, DiscreteMeanCenterConfig,\n",
    "    RadiusAttentionWeights, RadiusMaskConfig\n",
    ")\n",
    "\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Anzahl der trainierbaren Parameter im Modell zählen\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def create_kmeans_hrm_config(input_dim: int, edge_dim: int, hidden_dim: int = 128, latent_dim: int = 128, output_dim: int = TARGET_DIM, k: int = K_HEADS) -> KMeansHRMConfig:\n",
    "    \n",
    "    # Spectral Weighting Configuration\n",
    "    spectral_config = SpectralWeightingConfig(\n",
    "        node_channels=latent_dim,\n",
    "        K=3,  # Chebyshev polynomial order\n",
    "        num_layers=2,\n",
    "        normalization='sym',\n",
    "        bias=True,\n",
    "        dropout=0.2,\n",
    "        norm='batch',\n",
    "        norm_kwargs={'in_channels': latent_dim}\n",
    "    )\n",
    "    \n",
    "    # Center Module Configuration\n",
    "    center_config = DiscreteMeanCenterConfig(\n",
    "        distance_metric='euclidean'\n",
    "    )\n",
    "    \n",
    "    # Radius Mask Configuration (simplified weighting module)\n",
    "    radius_weighting = GATConv(latent_dim, latent_dim)\n",
    "    radius_config = RadiusMaskConfig(\n",
    "        max_num_neighbors=25,\n",
    "        radius=20,\n",
    "        weighting_module=radius_weighting,\n",
    "        threshold=0.1,\n",
    "        node_dim=latent_dim\n",
    "    )\n",
    "    \n",
    "    # KMeans Head Configuration\n",
    "    kmeans_head_config = KMeansHeadConfig(\n",
    "        node_count=k,\n",
    "        node_dim=latent_dim,\n",
    "        max_nodes=100,  \n",
    "        num_layers=5,\n",
    "        dropout=0.2,\n",
    "        weighting_module=SpectralWeighting(spectral_config),\n",
    "        center_module=DiscreteMeanCenter(center_config),\n",
    "        mask_module=RadiusAttentionWeights(radius_config),\n",
    "        act='relu',\n",
    "        act_kwargs={}\n",
    "    )\n",
    "    \n",
    "    # KMeans Configuration\n",
    "    kmeans_config = KMeansConfig(\n",
    "        k=k,\n",
    "        max_iter=10,\n",
    "        thresh=1e-6,\n",
    "        max_overlap=2,\n",
    "        head_module=kmeans_head_config,\n",
    "        excluded_is_cluster=True\n",
    "    )\n",
    "    \n",
    "    # Output Head Configuration\n",
    "    output_head_config = OutputHeadConfig(\n",
    "        node_dim=latent_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        output_dim=output_dim,\n",
    "        pooling_type='mean',\n",
    "        norm='batch',\n",
    "        norm_kwargs={'in_channels': hidden_dim},\n",
    "        act='relu',\n",
    "        act_kwargs={}\n",
    "    )\n",
    "    \n",
    "    # Policy Module Configuration (für Halt-Entscheidungen)\n",
    "    policy_config = OutputHeadConfig(\n",
    "        node_dim=latent_dim,\n",
    "        hidden_dim=hidden_dim//2,\n",
    "        output_dim=2,  # halt=0, continue=1\n",
    "        pooling_type='mean',\n",
    "        norm='batch',\n",
    "        norm_kwargs={'in_channels': hidden_dim//2},\n",
    "        act='relu',\n",
    "        act_kwargs={}\n",
    "    )\n",
    "    \n",
    "    # Inner Module Configuration\n",
    "    inner_config = KMeansHRMInnerModuleConfig(\n",
    "        add_self_loops=True,\n",
    "        add_negative_edges=True,\n",
    "        dropout=0.2,\n",
    "        hidden_dim=hidden_dim,        # inner-side hidden size, reused\n",
    "        node_dim=latent_dim,          # must equal vgae_latent_dim\n",
    "        attention_dim=16,           # bigger in final\n",
    "        edge_dim=edge_dim,\n",
    "        layers=3,\n",
    "        kmeans_config=kmeans_config,\n",
    "        output_head_config=output_head_config,\n",
    "        policy_module_config=policy_config,\n",
    "        K_cycles=2,\n",
    "        L_cycles=2,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        halt_max_steps=5,\n",
    "        halt_exploration_prob=0.1,\n",
    "    )\n",
    "    \n",
    "    # Hauptkonfiguration\n",
    "    config = KMeansHRMConfig(\n",
    "        inner_module=inner_config,\n",
    "        explore_steps_prob=0.1,\n",
    "        halt_max_steps=5,\n",
    "        pre_encoder_conv_layers=2,\n",
    "        vgae_encoder_type=\"cheb\",\n",
    "        input_dim=input_dim,\n",
    "        edge_attr_dim=edge_dim,\n",
    "        vgae_latent_dim=latent_dim,           # must equal inner.node_dim\n",
    "        vgae_encoder_layers=2,\n",
    "        vgae_encoder_dropout=0.1,\n",
    "        vgae_decoder_type=None,\n",
    "        vgae_kl_weight=1.0,\n",
    "    )\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Modell initialisieren\n",
    "hrm_config = create_kmeans_hrm_config(INPUT_DIM, EDGE_DIM, latent_dim=4, hidden_dim=4, output_dim=TARGET_DIM, k=2)\n",
    "model = KMeansHRMModule(hrm_config, training=True).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Print number of parameters\n",
    "num_params = count_parameters(model)\n",
    "print(f\"KMeansHRMModule created with {num_params:,} trainable parameters\")\n",
    "print(f\"Model size: {num_params * 4 / 1024 / 1024:.2f} MB (float32)\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e7e6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss and metrics initialized.\n"
     ]
    }
   ],
   "source": [
    "# Loss: Range-violation for missing, otherwise MSE\n",
    "# Note: HRM-repo inspiration (loss splitting, early checkpoints), see links below\n",
    "# - losses.py and pretrain.py from HRM (only as idea source)\n",
    "import numpy as np\n",
    "from typing import Union, List\n",
    "from training_loops import composite_loss, compute_mae_in_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87fb36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing new carry for batch 1827\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from training_loops import composite_loss, compute_mae_in_bounds, init_property_bounds\n",
    "\n",
    "init_property_bounds(PROPERTIES, extended_df)\n",
    "\n",
    "\n",
    "def save_checkpoint(state: Dict, step: int, is_best: bool = False):\n",
    "    path = os.path.join(CHECKPOINT_DIR, f\"step_{step}.pt\")\n",
    "    torch.save(state, path)\n",
    "    if is_best:\n",
    "        best_path = os.path.join(CHECKPOINT_DIR, \"best.pt\")\n",
    "        torch.save(state, best_path)\n",
    "\n",
    "\n",
    "class PretrainConfig(TypedDict):\n",
    "    # Data\n",
    "    data_path: str\n",
    "\n",
    "    # Hyperparams\n",
    "    global_batch_size: int\n",
    "    epochs: int\n",
    "    total_iters: int\n",
    "\n",
    "    lr: float\n",
    "    lr_min_ratio: float\n",
    "    lr_warmup_steps: int\n",
    "\n",
    "    weight_decay: float\n",
    "    beta1: float\n",
    "    beta2: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainState:\n",
    "    model: nn.Module\n",
    "    optimizer: torch.optim.Optimizer\n",
    "    carry: KMeansHRMInitialCarry | None\n",
    "\n",
    "    step: int\n",
    "    total_steps: int\n",
    "\n",
    "\n",
    "def compute_warmup_weight(step: int, warmup_steps: int, min_ratio: float) -> float:\n",
    "    if warmup_steps <= 0:\n",
    "        return 1.0\n",
    "    if step < warmup_steps:\n",
    "        # Linear warmup from min_ratio -> 1.0\n",
    "        return float(min_ratio + (1.0 - min_ratio) * (step / max(1, warmup_steps)))\n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def pack_train_state_for_save(ts: TrainState) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"step\": int(ts.step),\n",
    "        \"total_steps\": int(ts.total_steps),\n",
    "        # Carry can be large; still useful for exact resume within the same batch sequence\n",
    "        \"carry\": ts.carry,\n",
    "    }\n",
    "\n",
    "\n",
    "def train_batch(epoch: int, train_state: TrainState, batch_data: Batch, config: PretrainConfig) -> Dict[str, float]:\n",
    "    model = train_state.model\n",
    "    optimizer = train_state.optimizer\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Targets [B,5]\n",
    "    y = torch.stack([g.y for g in batch_data.to_data_list()], dim=0).to(device)\n",
    "    batch_data = batch_data.to(device)\n",
    "    related_info = batch_data.aux_info\n",
    "\n",
    "    # Reuse existing carry if provided; otherwise initialize\n",
    "    if train_state.carry is None:\n",
    "        print(f\"Initializing new carry for batch {batch_data.batch.shape[0]}\")\n",
    "        train_state.carry = model.initial_carry(batch_data)\n",
    "\n",
    "    # Forward\n",
    "    train_state.carry, hrm_output = model(train_state.carry, batch_data)\n",
    "    preds = hrm_output['y_pred']\n",
    "    policy = hrm_output['q_policy']\n",
    "    target_policy = hrm_output['target_q_policy']\n",
    "\n",
    "    loss = composite_loss(0, PROPERTIES, preds, y, related_info)\n",
    "    q_loss = composite_loss(0, PROPERTIES, policy, target_policy, related_info)\n",
    "    loss = loss + q_loss\n",
    "\n",
    "    train_state.step += 1\n",
    "    warmup_w = compute_warmup_weight(train_state.step, config[\"lr_warmup_steps\"], config[\"lr_min_ratio\"])  # type: ignore[index]\n",
    "    scaled_loss = loss * warmup_w * (1.0 / TOTAL_BATCH_COUNT)\n",
    "\n",
    "    # Backward/update\n",
    "    optimizer.zero_grad()\n",
    "    scaled_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Metrics (unscaled loss for logging)\n",
    "    with torch.no_grad():\n",
    "        metrics = compute_mae_in_bounds(0, PROPERTIES, preds, y, related_info)\n",
    "        metrics.update({\n",
    "            \"loss\": loss.item(),\n",
    "            \"warmup_weight\": float(warmup_w),\n",
    "        })\n",
    "\n",
    "\n",
    "    # Periodic checkpoint\n",
    "    global_step = train_state.step\n",
    "    if global_step % CHECKPOINT_EVERY_N_STEPS == 0:\n",
    "        save_checkpoint({\n",
    "            \"epoch\": epoch,\n",
    "            \"global_step\": global_step,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"model_class\": model.__class__.__name__,\n",
    "            \"model_module\": model.__class__.__module__,\n",
    "            \"train_state\": pack_train_state_for_save(train_state),\n",
    "        }, step=global_step)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(epoch: int, model: nn.Module, loader: DataLoader) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    mae_accum = {f\"mae_{p}\": 0.0 for p in PROPERTIES}\n",
    "    count_samples = 0\n",
    "\n",
    "    for batch_data in loader:\n",
    "        y = torch.stack([g.y for g in batch_data.to_data_list()], dim=0).to(device)\n",
    "        batch_data = batch_data.to(device)\n",
    "        related_info = batch_data.aux_info\n",
    "        \n",
    "        carry = model.initial_carry(batch_data)\n",
    "        _, hrm_output = model(carry, batch_data)\n",
    "        preds = hrm_output['y_pred']\n",
    "        policy = hrm_output['q_policy']\n",
    "        target_policy = hrm_output['target_q_policy']\n",
    "\n",
    "        loss = composite_loss(0, PROPERTIES, preds, y, related_info)\n",
    "        q_loss = composite_loss(0, PROPERTIES, policy, target_policy, related_info)\n",
    "        loss = loss + q_loss\n",
    "\n",
    "        metrics = compute_mae_in_bounds(0, PROPERTIES, preds, y, related_info)\n",
    "        for k, v in metrics.items():\n",
    "            if not math.isnan(v):\n",
    "                mae_accum[k] += v * preds.size(0)\n",
    "        running_loss += loss.item() * preds.size(0)\n",
    "        count_samples += preds.size(0)\n",
    "\n",
    "    avg_loss = running_loss / max(1, count_samples)\n",
    "    avg_mae = {k: (v / max(1, count_samples)) for k, v in mae_accum.items()}\n",
    "\n",
    "    return {\"loss\": avg_loss, **avg_mae}\n",
    "\n",
    "\n",
    "# Build a minimal config for warmup from existing hyperparams\n",
    "CONFIG: PretrainConfig = {\n",
    "    \"data_path\": DATA_CSV,\n",
    "    \"global_batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    # Step-based training support; used by helper loop\n",
    "    \"total_iters\": int(EPOCHS * len(train_loader)),\n",
    "    \"lr\": LR,\n",
    "    \"lr_min_ratio\": 0.1,\n",
    "    \"lr_warmup_steps\": max(1, len(train_loader) * 2),  # warm up first ~2 epochs of steps\n",
    "    \"weight_decay\": WEIGHT_DECAY,\n",
    "    \"beta1\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "}\n",
    "\n",
    "\n",
    "history = {\"train\": [], \"val\": []}\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "# Initialize TrainState with total steps estimated from loader length and epochs\n",
    "train_state = TrainState(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    carry=None,\n",
    "    step=0,\n",
    "    total_steps=CONFIG[\"epochs\"] * len(train_loader)\n",
    ")\n",
    "\n",
    "for epoch in range(1, CONFIG[\"epochs\"] + 1):\n",
    "    # Accumulators for epoch\n",
    "    running_loss = 0.0\n",
    "    mae_accum = {f\"mae_{p}\": 0.0 for p in PROPERTIES}\n",
    "    count_samples = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        metrics = train_batch(epoch, train_state, batch_data, CONFIG)\n",
    "        batch_size_effective = batch_data.num_graphs if hasattr(batch_data, 'num_graphs') else BATCH_SIZE\n",
    "\n",
    "        running_loss += metrics[\"loss\"] * batch_size_effective\n",
    "        for k in list(mae_accum.keys()):\n",
    "            prop_name = k.split(\"mae_\")[-1]\n",
    "            if f\"mae_{prop_name}\" in metrics and not math.isnan(metrics[f\"mae_{prop_name}\"]):\n",
    "                mae_accum[k] += metrics[f\"mae_{prop_name}\"] * batch_size_effective\n",
    "        count_samples += batch_size_effective\n",
    "\n",
    "    train_stats = {\n",
    "        \"loss\": running_loss / max(1, count_samples),\n",
    "        **{k: (v / max(1, count_samples)) for k, v in mae_accum.items()},\n",
    "    }\n",
    "\n",
    "    val_stats = validate(epoch, train_state.model, val_loader)\n",
    "\n",
    "    history[\"train\"].append({\"epoch\": epoch, **train_stats})\n",
    "    history[\"val\"].append({\"epoch\": epoch, **val_stats})\n",
    "\n",
    "    is_best = val_stats[\"loss\"] < best_val_loss\n",
    "    if is_best:\n",
    "        best_val_loss = val_stats[\"loss\"]\n",
    "\n",
    "    save_checkpoint({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": train_state.model.state_dict(),\n",
    "        \"optimizer_state\": train_state.optimizer.state_dict(),\n",
    "        \"train_stats\": train_stats,\n",
    "        \"val_stats\": val_stats,\n",
    "        \"model_class\": train_state.model.__class__.__name__,\n",
    "        \"model_module\": train_state.model.__class__.__module__,\n",
    "        \"train_state\": pack_train_state_for_save(train_state),\n",
    "    }, step=epoch, is_best=is_best)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | train_loss={train_stats['loss']:.4f} | val_loss={val_stats['loss']:.4f}\")\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6d629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_loops import load_checkpoint\n",
    "import glob\n",
    "\n",
    "# Restore model/optimizer/train_state from a checkpoint (best.pt preferred)\n",
    "best_path = os.path.join(CHECKPOINT_DIR, \"best.pt\")\n",
    "chosen_path = None\n",
    "if os.path.isfile(best_path):\n",
    "    chosen_path = best_path\n",
    "else:\n",
    "    candidates = sorted(glob.glob(os.path.join(CHECKPOINT_DIR, \"step_*.pt\")))\n",
    "    if len(candidates) > 0:\n",
    "        # Choose the numerically largest step\n",
    "        def _step_num(p):\n",
    "            try:\n",
    "                base = os.path.basename(p)\n",
    "                num = int(base.replace(\"step_\", \"\").replace(\".pt\", \"\"))\n",
    "                return num\n",
    "            except Exception:\n",
    "                return -1\n",
    "        candidates.sort(key=_step_num)\n",
    "        chosen_path = candidates[-1]\n",
    "\n",
    "if chosen_path:\n",
    "    raw_state, saved_ts = load_checkpoint(chosen_path, model, optimizer, map_location=device)\n",
    "    if isinstance(saved_ts, dict):\n",
    "        try:\n",
    "            train_state.step = int(saved_ts.get(\"step\", train_state.step))\n",
    "            train_state.total_steps = int(saved_ts.get(\"total_steps\", train_state.total_steps))\n",
    "            train_state.carry = saved_ts.get(\"carry\", None)\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(f\"Loaded checkpoint: {chosen_path} | step={train_state.step}\")\n",
    "else:\n",
    "    print(\"No checkpoint found to load.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_loops import train_until_total_iters\n",
    "\n",
    "# If you want to override step budget, set CONFIG[\"total_iters\"] directly\n",
    "TOTAL_ITERS = int(CONFIG.get(\"total_iters\", EPOCHS * len(train_loader)))\n",
    "print(f\"Training until total_iters = {TOTAL_ITERS}\")\n",
    "\n",
    "# Run the total_iters-driven loop\n",
    "history_step, best_val_loss = train_until_total_iters(\n",
    "    total_iters=TOTAL_ITERS,\n",
    "    start_epoch=1,\n",
    "    train_state=train_state,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    config=CONFIG,\n",
    "    train_batch_fn=train_batch,\n",
    "    validate_fn=validate,\n",
    "    save_checkpoint_fn=save_checkpoint,\n",
    "    checkpoint_every_n=CHECKPOINT_EVERY_N_STEPS,\n",
    "    print_every_n=25,\n",
    ")\n",
    "\n",
    "# Merge history into the existing one for convenience\n",
    "history[\"train\"].extend(history_step[\"train\"])  # type: ignore[index]\n",
    "history[\"val\"].extend(history_step[\"val\"])      # type: ignore[index]\n",
    "print(f\"Done total_iters training. best_val_loss={best_val_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b0f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "metrics_path = os.path.join(CHECKPOINT_DIR, \"history.json\")\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "print(f\"Saved metrics to {metrics_path}\")\n",
    "\n",
    "# Plot\n",
    "def plot_curves(history):\n",
    "    epochs = [e[\"epoch\"] for e in history[\"train\"]]\n",
    "    train_losses = [e[\"loss\"] for e in history[\"train\"]]\n",
    "    val_losses = [e[\"loss\"] for e in history[\"val\"]]\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(epochs, train_losses, label=\"train_loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"val_loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
